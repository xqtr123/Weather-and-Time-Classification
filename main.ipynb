{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = pd.read_json('../train_dataset/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 'train_images\\\\00001.jpg',\n",
       " 'period': 'Morning',\n",
       " 'weather': 'Cloudy'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改成图片的路径格式\n",
    "train_json['filename'] = train_json['annotations'].apply(lambda x : x['filename'].replace('\\\\', '/'))\n",
    "train_json['period'] = train_json['annotations'].apply(lambda x : x['period'])\n",
    "train_json['weather'] = train_json['annotations'].apply(lambda x : x['weather'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>filename</th>\n",
       "      <th>period</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'filename': 'train_images\\00001.jpg', 'period...</td>\n",
       "      <td>train_images/00001.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'filename': 'train_images\\00002.jpg', 'period...</td>\n",
       "      <td>train_images/00002.jpg</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'filename': 'train_images\\00003.jpg', 'period...</td>\n",
       "      <td>train_images/00003.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'filename': 'train_images\\00004.jpg', 'period...</td>\n",
       "      <td>train_images/00004.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'filename': 'train_images\\00005.jpg', 'period...</td>\n",
       "      <td>train_images/00005.jpg</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         annotations                filename  \\\n",
       "0  {'filename': 'train_images\\00001.jpg', 'period...  train_images/00001.jpg   \n",
       "1  {'filename': 'train_images\\00002.jpg', 'period...  train_images/00002.jpg   \n",
       "2  {'filename': 'train_images\\00003.jpg', 'period...  train_images/00003.jpg   \n",
       "3  {'filename': 'train_images\\00004.jpg', 'period...  train_images/00004.jpg   \n",
       "4  {'filename': 'train_images\\00005.jpg', 'period...  train_images/00005.jpg   \n",
       "\n",
       "      period weather  \n",
       "0    Morning  Cloudy  \n",
       "1  Afternoon  Cloudy  \n",
       "2    Morning  Cloudy  \n",
       "3    Morning   Sunny  \n",
       "4  Afternoon  Cloudy  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标签编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签编码\n",
    "train_json['period'], period_dict = pd.factorize(train_json['period'])\n",
    "train_json['weather'], weather_dict = pd.factorize(train_json['weather'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Morning', 'Afternoon', 'Dawn', 'Dusk'], dtype='object'),\n",
       " Index(['Cloudy', 'Sunny', 'Rainy'], dtype='object'))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_dict,weather_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1613\n",
       "1     829\n",
       "3     124\n",
       "2      34\n",
       "Name: period, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json['period'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1119\n",
       "1     886\n",
       "2     595\n",
       "Name: weather, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json['weather'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据进行处理，首先得到数据，包括数据路径和数据的标签，对标签进行编码，对标签进行统计，部分标签对应数据过少，可对数据进行增强。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>filename</th>\n",
       "      <th>period</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'filename': 'train_images\\00001.jpg', 'period...</td>\n",
       "      <td>train_images/00001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'filename': 'train_images\\00002.jpg', 'period...</td>\n",
       "      <td>train_images/00002.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'filename': 'train_images\\00003.jpg', 'period...</td>\n",
       "      <td>train_images/00003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'filename': 'train_images\\00004.jpg', 'period...</td>\n",
       "      <td>train_images/00004.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'filename': 'train_images\\00005.jpg', 'period...</td>\n",
       "      <td>train_images/00005.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>{'filename': 'train_images\\02996.jpg', 'period...</td>\n",
       "      <td>train_images/02996.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>{'filename': 'train_images\\02997.jpg', 'period...</td>\n",
       "      <td>train_images/02997.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>{'filename': 'train_images\\02998.jpg', 'period...</td>\n",
       "      <td>train_images/02998.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>{'filename': 'train_images\\02999.jpg', 'period...</td>\n",
       "      <td>train_images/02999.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>{'filename': 'train_images\\03000.jpg', 'period...</td>\n",
       "      <td>train_images/03000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            annotations  \\\n",
       "0     {'filename': 'train_images\\00001.jpg', 'period...   \n",
       "1     {'filename': 'train_images\\00002.jpg', 'period...   \n",
       "2     {'filename': 'train_images\\00003.jpg', 'period...   \n",
       "3     {'filename': 'train_images\\00004.jpg', 'period...   \n",
       "4     {'filename': 'train_images\\00005.jpg', 'period...   \n",
       "...                                                 ...   \n",
       "2595  {'filename': 'train_images\\02996.jpg', 'period...   \n",
       "2596  {'filename': 'train_images\\02997.jpg', 'period...   \n",
       "2597  {'filename': 'train_images\\02998.jpg', 'period...   \n",
       "2598  {'filename': 'train_images\\02999.jpg', 'period...   \n",
       "2599  {'filename': 'train_images\\03000.jpg', 'period...   \n",
       "\n",
       "                    filename  period  weather  \n",
       "0     train_images/00001.jpg       0        0  \n",
       "1     train_images/00002.jpg       1        0  \n",
       "2     train_images/00003.jpg       0        0  \n",
       "3     train_images/00004.jpg       0        1  \n",
       "4     train_images/00005.jpg       1        0  \n",
       "...                      ...     ...      ...  \n",
       "2595  train_images/02996.jpg       1        1  \n",
       "2596  train_images/02997.jpg       0        2  \n",
       "2597  train_images/02998.jpg       0        2  \n",
       "2598  train_images/02999.jpg       0        2  \n",
       "2599  train_images/03000.jpg       1        1  \n",
       "\n",
       "[2600 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super(WeatherDataset, self).__init__()\n",
    "        self.df = df\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize(size=(100, 100)),\n",
    "            T.RandomCrop(size=(64, 64)),  # 随即裁剪\n",
    "            T.RandomRotation(10),   # 在(-10, 10)之间旋转一定角度\n",
    "            T.RandomHorizontalFlip(),   # 按照0.5的概率对图片进行水平翻转\n",
    "            T.RandomVerticalFlip(),     # 按照0.5的概率对图片进行垂直翻转\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = '../train_dataset/' + self.df['filename'].iloc[index]\n",
    "        img = Image.open(file_name)\n",
    "        img = self.transform(img)\n",
    "        return img, torch.tensor(self.df['period'].iloc[index]), torch.tensor(self.df['weather'].iloc[index])\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WeatherDataset(train_json.iloc[:-500])\n",
    "val_dataset = WeatherDataset(train_json.iloc[-500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0]\n",
    "# import cv2\n",
    "# # image = cv2.imread()\n",
    "# cv2.imshow('image', train_dataset[0][0].numpy())\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for x, y1, y1 in train_dataset:\n",
    "    i+=1\n",
    "    print(x.shape)\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WeatherModel, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, 11, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(6400, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 10)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(10, 4)\n",
    "        self.fc2 = nn.Linear(10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        fc = self.fc(out)\n",
    "        logist1 = self.fc1(fc)\n",
    "        logist2 = self.fc2(fc)\n",
    "        return logist1, logist2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from d2l import torch as d2l\n",
    "import d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单个残差块\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,use_1x1conv=False, stride=1):\n",
    "        super(Residual, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels,kernel_size=3,padding=1, stride=stride)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self,X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        return F.relu(Y + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n",
    "    if first_block:\n",
    "        assert in_channels == out_channels # 第一个模块的通道数和输入通道数一致\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_channels, out_channels))\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add_module('resnet_block1', resnet_block(64, 64, 2, first_block=True))\n",
    "net.add_module('resnet_block2', resnet_block(64, 128, 2))\n",
    "net.add_module('resnet_block3', resnet_block(128, 256, 2))\n",
    "net.add_module('resnet_block4', resnet_block(256, 512, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add_module('global_avg_pool', nn.AdaptiveAvgPool2d((1, 1)))\n",
    "net.add_module('fc', nn.Sequential(nn.Flatten(),nn.Linear(512, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self, net):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.resnet = net\n",
    "        self.fc1 = nn.Linear(10, 4)\n",
    "        self.fc2 = nn.Linear(10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fc = self.resnet(x)\n",
    "        logist1 = self.fc1(fc)\n",
    "        logist2 = self.fc2(fc)\n",
    "        return logist1, logist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4257, -0.3799, -0.2771, -0.6143],\n",
       "         [-0.5950, -0.3372, -0.1151, -0.7659],\n",
       "         [-0.4305, -0.3472, -0.0273, -0.7403],\n",
       "         [-0.5373, -0.2308, -0.0327, -0.6800],\n",
       "         [-0.6122, -0.3049, -0.1851, -0.5699],\n",
       "         [-0.5881, -0.3708, -0.1312, -0.7301],\n",
       "         [-0.3884, -0.4392, -0.2811, -0.4558],\n",
       "         [-0.4902, -0.3314, -0.0932, -0.5333],\n",
       "         [-0.4184, -0.4402, -0.1186, -0.6483],\n",
       "         [-0.4304, -0.5231, -0.3442, -0.6360]], grad_fn=<AddmmBackward>),\n",
       " tensor([[ 0.2695, -0.3989, -0.4391],\n",
       "         [ 0.0912, -0.0531, -0.4529],\n",
       "         [ 0.0395,  0.0250, -0.2708],\n",
       "         [ 0.0369, -0.2127, -0.4743],\n",
       "         [ 0.3085, -0.2855, -0.5756],\n",
       "         [ 0.1680, -0.1040, -0.5745],\n",
       "         [ 0.2825, -0.2198, -0.3281],\n",
       "         [ 0.1078, -0.0704, -0.3495],\n",
       "         [ 0.2706, -0.1155, -0.3780],\n",
       "         [ 0.0592, -0.2060, -0.3371]], grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Resnet(net)\n",
    "model(torch.tensor(np.random.rand(10, 3, 64, 64).astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2455,  0.1682, -0.1396,  0.0274],\n",
       "         [-0.2413,  0.1612, -0.1377,  0.0333],\n",
       "         [-0.2410,  0.1672, -0.1421,  0.0310],\n",
       "         [-0.2385,  0.1656, -0.1373,  0.0261],\n",
       "         [-0.2299,  0.1703, -0.1443,  0.0255],\n",
       "         [-0.2295,  0.1755, -0.1448,  0.0419],\n",
       "         [-0.2431,  0.1761, -0.1399,  0.0323],\n",
       "         [-0.2344,  0.1711, -0.1449,  0.0349],\n",
       "         [-0.2385,  0.1760, -0.1510,  0.0359],\n",
       "         [-0.2410,  0.1631, -0.1322,  0.0277]], grad_fn=<AddmmBackward>),\n",
       " tensor([[ 0.2052, -0.2900, -0.2383],\n",
       "         [ 0.2053, -0.2857, -0.2382],\n",
       "         [ 0.2077, -0.2870, -0.2365],\n",
       "         [ 0.2046, -0.2813, -0.2401],\n",
       "         [ 0.2085, -0.2813, -0.2352],\n",
       "         [ 0.2179, -0.2713, -0.2376],\n",
       "         [ 0.2059, -0.2716, -0.2391],\n",
       "         [ 0.2104, -0.2767, -0.2390],\n",
       "         [ 0.2065, -0.2758, -0.2404],\n",
       "         [ 0.2014, -0.2870, -0.2359]], grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WeatherModel()\n",
    "model(torch.tensor(np.random.rand(10, 3, 224, 224).astype(np.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:0\n",
      "Loss:1.89421/1.81712\n",
      "period acc:0.61032/0.57166\n",
      "weather acc:0.58428/0.57497\n",
      "\n",
      "Epoch:1\n",
      "Loss:1.56799/1.60033\n",
      "period acc:0.61648/0.60472\n",
      "weather acc:0.69934/0.62861\n",
      "\n",
      "Epoch:2\n",
      "Loss:1.48690/1.67217\n",
      "period acc:0.62263/0.55709\n",
      "weather acc:0.72775/0.64934\n",
      "\n",
      "Epoch:3\n",
      "Loss:1.44197/1.77010\n",
      "period acc:0.64820/0.61929\n",
      "weather acc:0.75095/0.56280\n",
      "\n",
      "Epoch:4\n",
      "Loss:1.37810/1.42768\n",
      "period acc:0.65956/0.66316\n",
      "weather acc:0.76089/0.71139\n",
      "\n",
      "Epoch:5\n",
      "Loss:1.29845/1.42596\n",
      "period acc:0.67330/0.69922\n",
      "weather acc:0.77462/0.67142\n",
      "\n",
      "Epoch:6\n",
      "Loss:1.28466/1.60822\n",
      "period acc:0.67140/0.67924\n",
      "weather acc:0.78977/0.62410\n",
      "\n",
      "Epoch:7\n",
      "Loss:1.25570/1.50190\n",
      "period acc:0.68229/0.67593\n",
      "weather acc:0.79782/0.71319\n",
      "\n",
      "Epoch:8\n",
      "Loss:1.26722/1.51606\n",
      "period acc:0.67708/0.65325\n",
      "weather acc:0.78693/0.67203\n",
      "\n",
      "Epoch:9\n",
      "Loss:1.16584/1.54040\n",
      "period acc:0.70739/0.69651\n",
      "weather acc:0.80208/0.63131\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for epoch in range(10):\n",
    "    train_loss, val_loss = [], []\n",
    "    train_acc1, train_acc2 = [], []\n",
    "    val_acc1, val_acc2 = [], []\n",
    "\n",
    "    model.train()\n",
    "    for i, (x, y1, y2) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        y1 = y1.to(device)\n",
    "        y2 = y2.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred1, pred2 = model(x)\n",
    "        loss = criterion(pred1, y1) + criterion(pred2, y2)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc1.append((pred1.argmax(1) == y1.flatten()).cpu().numpy().mean())\n",
    "        train_acc2.append((pred2.argmax(1) == y2.flatten()).cpu().numpy().mean())\n",
    "\n",
    "    model.eval()\n",
    "    for i,(x, y1, y2) in enumerate(val_loader):\n",
    "        x = x.to(device)\n",
    "        y1 = y1.to(device)\n",
    "        y2 = y2.to(device)\n",
    "        pred1, pred2 = model(x)\n",
    "        loss = criterion(pred1, y1) + criterion(pred2, y2)\n",
    "        val_loss.append(loss.item())\n",
    "        val_acc1.append((pred1.argmax(1) == y1.flatten()).cpu().numpy().mean())\n",
    "        val_acc2.append((pred2.argmax(1) == y2.flatten()).cpu().numpy().mean())\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'\\nEpoch:{epoch}')\n",
    "        print(f'Loss:{np.mean(train_loss):3.5f}/{np.mean(val_loss):3.5f}')\n",
    "        print(f'period acc:{np.mean(train_acc1):3.5f}/{np.mean(val_acc1):3.5f}')\n",
    "        print(f'weather acc:{np.mean(train_acc2):3.5f}/{np.mean(val_acc2):3.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'alexnet.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-239e83f3e16f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'alexnet.pth'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# torch.save(model.state_dict(), path)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\1program\\1python\\anaconda\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\1program\\1python\\anaconda\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\1program\\1python\\anaconda\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'alexnet.pth'"
     ]
    }
   ],
   "source": [
    "path = 'alexnet.pth'\n",
    "# torch.save(model.state_dict(), path)\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-77c88aac46cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\1program\\1python\\anaconda\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-87-686ce8320b63>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mlogist1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mlogist2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\1program\\1python\\anaconda\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\1program\\1python\\anaconda\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\1program\\1python\\anaconda\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\1program\\1python\\anaconda\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\1program\\1python\\anaconda\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 440\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "model(torch.tensor(np.random.rand(10, 3, 224, 224).astype(np.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测与提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "test_df = pd.DataFrame({'filename': glob.glob('../test_dataset/test_images/*.jpg')})\n",
    "test_df['period'] = 0\n",
    "test_df['weather'] = 0\n",
    "test_df = test_df.sort_values(by = 'filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WeatherDataset(test_df)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "period_pred = []\n",
    "weather_pred = []\n",
    "for i, (x, y1, y2) in enumerate(test_dataloader):\n",
    "    x = x.to(device)\n",
    "    y1 = y1.to(device)\n",
    "    y2 = y2.to(device)\n",
    "    pred1, pred2 = model(x)\n",
    "    period_pred += period_dict[pred1.argmax(1).cpu().numpy()].tolist()\n",
    "    weather_pred += weather_dict[pred2.argmax(1).cpu().numpy()].tolist()\n",
    "\n",
    "test_df['period'] = period_pred\n",
    "test_df['weather'] = weather_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>period</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../test_dataset/test_images\\00008.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../test_dataset/test_images\\00018.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../test_dataset/test_images\\00020.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../test_dataset/test_images\\00022.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../test_dataset/test_images\\00035.jpg</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>../test_dataset/test_images\\02970.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>../test_dataset/test_images\\02973.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>../test_dataset/test_images\\02976.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>../test_dataset/test_images\\02988.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>../test_dataset/test_images\\02994.jpg</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filename     period weather\n",
       "0    ../test_dataset/test_images\\00008.jpg    Morning  Cloudy\n",
       "1    ../test_dataset/test_images\\00018.jpg    Morning  Cloudy\n",
       "2    ../test_dataset/test_images\\00020.jpg    Morning  Cloudy\n",
       "3    ../test_dataset/test_images\\00022.jpg    Morning   Sunny\n",
       "4    ../test_dataset/test_images\\00035.jpg  Afternoon  Cloudy\n",
       "..                                     ...        ...     ...\n",
       "395  ../test_dataset/test_images\\02970.jpg    Morning   Sunny\n",
       "396  ../test_dataset/test_images\\02973.jpg    Morning  Cloudy\n",
       "397  ../test_dataset/test_images\\02976.jpg    Morning  Cloudy\n",
       "398  ../test_dataset/test_images\\02988.jpg    Morning  Cloudy\n",
       "399  ../test_dataset/test_images\\02994.jpg    Morning   Sunny\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_json = {'annotations':[]}\n",
    "for row in test_df.iterrows():\n",
    "    submit_json['annotations'].append({\n",
    "        'filename':'test_images\\\\' + row[1].filename.split('\\\\')[-1],\n",
    "        'period':row[1].period,\n",
    "        'weather':row[1].weather\n",
    "    })\n",
    "with open('submit.json', 'w') as up:\n",
    "    json.dump(submit_json, up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eedd4133f4b706b017dbfea8535950f8f8a4d5c818f0b07b22d819b4fab5ae93"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
